{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP37de6kn8cV42Qe0BQ+VM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mea2220/Interactive-Visualization-Lovable-Report/blob/main/Assignment_4_Alexander.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assignment 4 :: PySpark Data Queries"
      ],
      "metadata": {
        "id": "luzMAu72l7NN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Install PySpark (Python Spark API)**\n"
      ],
      "metadata": {
        "id": "tk_R4d5nl34A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5vG6bXSmI_J",
        "outputId": "77a40934-4dc3-4a10-a615-c9527fbe0917"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.9 (from pyspark)\n",
            "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813800 sha256=5a89290daf8692ca16619edc10600b7b72791b4237e8f4bf630bd8106b05f4f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9f/68/f89fb34ccd886909be7d0e390eaaf97f21efdf540c0ee8dbcd\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.1\n",
            "    Uninstalling pyspark-3.5.1:\n",
            "      Successfully uninstalled pyspark-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires pyspark[connect]~=3.5.1, but you have pyspark 4.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed py4j-0.10.9.9 pyspark-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ],
      "metadata": {
        "id": "9520KUFtmNJB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Intro to Apache Spark\") \\\n",
        "    .config(\"spark.cores.max\", \"4\") \\\n",
        "    .config('spark.executor.memory', '8G') \\\n",
        "    .config('spark.driver.maxResultSize', '8g') \\\n",
        "    .config('spark.kryoserializer.buffer.max', '512m') \\\n",
        "    .config(\"spark.driver.cores\", \"4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "print(\"Using Apache Spark Version\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SICeuo8mQrk",
        "outputId": "f5b7f049-63a3-4b9d-fbdf-a3b1cfb5f008"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Apache Spark Version 4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Ingest Data & Count Rows**\n"
      ],
      "metadata": {
        "id": "snYvOhwAsnFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the Crunchbase ODM Orgs CSV into a Spark DataFrame\n",
        "cb_sdf = spark.read.format(\"csv\") \\\n",
        "               .options(header='true', inferschema='true', treatEmptyValuesAsNulls='true') \\\n",
        "               .load(\"/content/crunchbase_odm_orgs.csv\")\n",
        "\n",
        "#Print the count of all records\n",
        "cb_sdf.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0d97pkclRMq",
        "outputId": "0aa5e3be-3901-4ca1-c178-8aa0d1436003"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1127735"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#see columns\n",
        "cb_sdf.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkX_sedBvTsc",
        "outputId": "ca117faa-ad8e-4261-94b1-f673e33c5a55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uuid',\n",
              " 'name',\n",
              " 'type',\n",
              " 'primary_role',\n",
              " 'cb_url',\n",
              " 'domain',\n",
              " 'homepage_url',\n",
              " 'logo_url',\n",
              " 'facebook_url',\n",
              " 'twitter_url',\n",
              " 'linkedin_url',\n",
              " 'combined_stock_symbols',\n",
              " 'city',\n",
              " 'region',\n",
              " 'country_code',\n",
              " 'short_description']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **A) Find all companies with names that contain exactly three words  (e.g. \"Fox Interactive Media\")**"
      ],
      "metadata": {
        "id": "cmw2DWoDsty2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06foxuISkaeB",
        "outputId": "057a882b-3996-4cad-d083-36986842494f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206299"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "##Print the count of such companies\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "three_word_companies = cb_sdf.filter(F.size(F.split(F.col(\"name\"), \" \")) == 3)\n",
        "three_word_companies.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Use show() to display only the name and location (city, region, country_code) in the resulting Spark DataFrame\n",
        "\n",
        "three_word_companies.select(\"name\", \"city\", \"region\", \"country_code\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD9vzr7ruodo",
        "outputId": "a4d223cd-c9d5-44db-dde2-836445d80797"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+----------------+------------+\n",
            "|                name|         city|          region|country_code|\n",
            "+--------------------+-------------+----------------+------------+\n",
            "|Fox Interactive M...|Beverly Hills|      California|         USA|\n",
            "|Hutchison Whampoa...|    Hong Kong|Hong Kong Island|         HKG|\n",
            "|      Gannett Co Inc|       Mclean|        Virginia|         USA|\n",
            "|          HOT or NOT|San Francisco|      California|         USA|\n",
            "|        Funny Or Die|    San Mateo|      California|         USA|\n",
            "|Peak Steal Buildings|       Morgan|         Georgia|         USA|\n",
            "|      Kosiso - store|      Chicago|        Illinois|         USA|\n",
            "|The Accelerator G...|       Mclean|        Virginia|         USA|\n",
            "|    Real Time Matrix|      Oakland|      California|         USA|\n",
            "|  Keep Highways Safe|   Jenkintown|    Pennsylvania|         USA|\n",
            "|    Red Light Center|         NULL|            NULL|        NULL|\n",
            "|    Small World Labs|       Austin|           Texas|         USA|\n",
            "|Sparta Social Net...|    Cambridge|   Massachusetts|         USA|\n",
            "|Web Scribble Solu...|         Troy|        New York|         USA|\n",
            "|     J Squared Media| Philadelphia|    Pennsylvania|         USA|\n",
            "|     Search to Phone|      Boulder|        Colorado|         USA|\n",
            "|Localcents, Inc. ...|      Boulder|        Colorado|         USA|\n",
            "| RegOnline by Lanyon|       Dallas|           Texas|         USA|\n",
            "|Shock Treatment M...|      Seattle|      Washington|         USA|\n",
            "|  Third Screen Media|       Boston|   Massachusetts|         USA|\n",
            "+--------------------+-------------+----------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **B) Find all companies located in the state of New Jersey:**"
      ],
      "metadata": {
        "id": "CCWs6WbFs8VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Print the count of such companies\n",
        "\n",
        "new_jersey_companies = cb_sdf.where((F.col('region') == \"New Jersey\"))\n",
        "\n",
        "new_jersey_companies.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE3YmVSokpFp",
        "outputId": "80a3eb5c-9364-4c04-e76c-1857ac791c3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10251"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Use show() to display only the name and location (city, region, country_code) in the resulting Spark DataFrame\n",
        "new_jersey_companies.select(\"name\", \"city\", \"region\", \"country_code\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R9aeCgiu8jY",
        "outputId": "c7400d80-146f-4319-f39f-acfbf4371dca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+----------+------------+\n",
            "|               name|          city|    region|country_code|\n",
            "+-------------------+--------------+----------+------------+\n",
            "|           Blogsigs|       Madison|New Jersey|         USA|\n",
            "|              MSNBC|      Secaucus|New Jersey|         USA|\n",
            "|            BitWine|       Tenafly|New Jersey|         USA|\n",
            "|          GoAmerica|    Hackensack|New Jersey|         USA|\n",
            "|          Phone.com|        Newark|New Jersey|         USA|\n",
            "|           Phanfare|     Princeton|New Jersey|         USA|\n",
            "|              Vidyo|    Hackensack|New Jersey|         USA|\n",
            "|          eventsbot|    Piscataway|New Jersey|         USA|\n",
            "|       CheerOutLoud|   Perth Amboy|New Jersey|         USA|\n",
            "|        Jet Numbers|East Brunswick|New Jersey|         USA|\n",
            "|       ShareMethods|  South Orange|New Jersey|         USA|\n",
            "|      Winescorecard|  Lambertville|New Jersey|         USA|\n",
            "|              ePrep|     Princeton|New Jersey|         USA|\n",
            "|     Origin Digital|     Weehawken|New Jersey|         USA|\n",
            "|     Atlantic Metro|    Parsippany|New Jersey|         USA|\n",
            "|             eLabor|      Roseland|New Jersey|         USA|\n",
            "|Ecommerce Solutions|      Whippany|New Jersey|         USA|\n",
            "|         HungryFlix|      Caldwell|New Jersey|         USA|\n",
            "|          GamerNook|    Toms River|New Jersey|         USA|\n",
            "|           ReefEdge|      Fort Lee|New Jersey|         USA|\n",
            "+-------------------+--------------+----------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **C) Add a \"TechDomain\" column to the DataFrame where the row entries are set to 1 if the \"domain\" field contains \"github.io\", and 0 otherwise:**"
      ],
      "metadata": {
        "id": "nHkb5-kctBPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_sdf_c = cb_sdf.withColumn(\n",
        "    'TechDomain',\n",
        "    F.when(F.col('domain').like('%github.io%'), 1).otherwise(0)\n",
        ")\n",
        "\n",
        "##Use show() to display only the name, location (city, region, country_code) and TechDomain column for companies where the TechDomain field is marked as 1.\n",
        "cb_sdf_c.filter(F.col('TechDomain') == 1).select('name', 'city', 'region', 'country_code', 'TechDomain').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_z3QUazlBf3",
        "outputId": "dd56bcc0-29cf-421e-b4db-72b33eb07777"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+------------+------------+----------+\n",
            "|                name|         city|      region|country_code|TechDomain|\n",
            "+--------------------+-------------+------------+------------+----------+\n",
            "|               OSSEC|San Francisco|  California|         USA|         1|\n",
            "|            Fosstrak|San Francisco|  California|         USA|         1|\n",
            "|       littlesnapper|         NULL|        NULL|        NULL|         1|\n",
            "|  Associação CRIArte|         NULL|        NULL|        NULL|         1|\n",
            "|           Bros Labs|        Hanoi|NA - Vietnam|         VNM|         1|\n",
            "|             Telcial|      Brenham|       Texas|         USA|         1|\n",
            "|      Dev Free Casts|         NULL|        NULL|        NULL|         1|\n",
            "|  Ojas Open Platform|San Francisco|  California|         USA|         1|\n",
            "|       Bababa Studio|San Francisco|  California|         USA|         1|\n",
            "|             Nova IO|San Francisco|  California|         USA|         1|\n",
            "|Zest - Discover E...|San Francisco|  California|         USA|         1|\n",
            "|         grokkerlabs|San Francisco|  California|         USA|         1|\n",
            "|       Heatwood Labs|San Francisco|  California|         USA|         1|\n",
            "|           Cobertura|San Francisco|  California|         USA|         1|\n",
            "|        TypeBound<T>|San Francisco|  California|         USA|         1|\n",
            "|            Fearless|San Francisco|  California|         USA|         1|\n",
            "|Century Holdings ...|    Las Vegas|      Nevada|         USA|         1|\n",
            "|            Hostabee|Saint-quentin| Rhone-Alpes|         FRA|         1|\n",
            "|        CoinOffering|         NULL|        NULL|        NULL|         1|\n",
            "|VanMobile Develop...|         NULL|        NULL|        NULL|         1|\n",
            "+--------------------+-------------+------------+------------+----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **D) Find all companies whose names contain at least one repeating consecutive letter (e.g., \"Google\", \"Twitter\", \"Massa Inc.\") using a Spark UDF function.**"
      ],
      "metadata": {
        "id": "PmzDkrlgtKFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import BooleanType\n",
        "import re\n",
        "\n",
        "# Define a Python function to check for repeating consecutive letters\n",
        "def has_repeating_letters(name):\n",
        "    if name is None:\n",
        "        return False\n",
        "    return bool(re.search(r'(.)\\1', name, re.IGNORECASE))\n",
        "\n",
        "# Register the Python function as a Spark UDF\n",
        "repeating_letters_udf = udf(has_repeating_letters, BooleanType())\n",
        "\n",
        "# Apply the UDF to the DataFrame and filter\n",
        "repeating_letter_companies = cb_sdf.filter(repeating_letters_udf(col(\"name\")))\n",
        "\n",
        "##Print the count of such companies\n",
        "repeating_letter_companies.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywd8fAlpkr2M",
        "outputId": "f13647f9-6e4d-4df5-dbd6-e6470c17728b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "275701"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Use show() to display only the name and location (city, region, country_code) in the resulting Spark DataFrame\n",
        "repeating_letter_companies.select(\"name\", \"city\", \"region\", \"country_code\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l8ZC2ccz0ys",
        "outputId": "6cd1c1c5-6543-47f1-fdf8-5b700c8ebb1a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------+-----------+------------+\n",
            "|                name|            city|     region|country_code|\n",
            "+--------------------+----------------+-----------+------------+\n",
            "|                Digg|        New York|   New York|         USA|\n",
            "|            Facebook|      Menlo Park| California|         USA|\n",
            "|               Accel|       Palo Alto| California|         USA|\n",
            "|             Twitter|   San Francisco| California|         USA|\n",
            "|             MeetMoi|        New York|   New York|         USA|\n",
            "|               Joost|        New York|   New York|         USA|\n",
            "|             AddThis|          Vienna|   Virginia|         USA|\n",
            "|               Thoof|          Austin|      Texas|         USA|\n",
            "|Hearst Communicat...|        New York|   New York|         USA|\n",
            "|      Gannett Co Inc|          Mclean|   Virginia|         USA|\n",
            "|            AllPeers|          Oxford|Oxfordshire|         GBR|\n",
            "| Aggregate Knowledge|       San Mateo| California|         USA|\n",
            "|              iSkoot|   San Francisco| California|         USA|\n",
            "|            AllofMP3|          Moscow|Moscow City|         RUS|\n",
            "|         Amie Street|Long Island City|   New York|         USA|\n",
            "|           Sellaband|          Berlin|     Berlin|         DEU|\n",
            "|        Funny Or Die|       San Mateo| California|         USA|\n",
            "|              MeeVee|      Burlingame| California|         USA|\n",
            "|          Legg Mason|       Baltimore|   Maryland|         USA|\n",
            "|              Zooomr|   San Francisco| California|         USA|\n",
            "+--------------------+----------------+-----------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}